{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidation(XTraining, kfold, modelName, model='default', verbose=False):\n",
    "    maeList = []\n",
    "    mapeList = []\n",
    "    rmseList = []\n",
    "\n",
    "    for k in reversed(range(1, kfold+1)):\n",
    "        if verbose:\n",
    "            print(f'\\nKFold Number: {k}')\n",
    "        # Start and End Date for Validation\n",
    "        startDateValid = XTraining['Date'].max() - datetime.timedelta(days=k*6*7)\n",
    "        endDateValid = XTraining['Date'].max() - datetime.timedelta(days=(k-1)*6*7)\n",
    "\n",
    "        # Filtering Dataset\n",
    "        training = XTraining[XTraining['Date'] < startDateValid]\n",
    "        validation = XTraining[(XTraining['Date'] >= startDateValid) & (XTraining['Date'] <= endDateValid)]\n",
    "\n",
    "        # Training and Validation Dataset\n",
    "        # Training\n",
    "        XKFoldTraining = training.drop(['Date', 'Sales'], axis=1)\n",
    "        yKFoldTraining = training['Sales']\n",
    "\n",
    "        # Validation\n",
    "        XKFoldValidation = validation.drop(['Date', 'Sales'], axis=1)\n",
    "        yKFoldValidation = validation['Sales']\n",
    "\n",
    "        # Model\n",
    "        ## Model Map\n",
    "        modelMap = {\n",
    "            'Linear Regression': LinearRegression(),\n",
    "            'Lasso': Lasso(alpha=0.01),\n",
    "            'Random Forest Regressor': RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42),\n",
    "            'XGBoost Regressor': xgb.XGBRegressor( objective='reg:squarederror', n_estimators=500, eta=0.01, max_depth=10, \n",
    "                                                      subsample=0.7, colsample_bytree=0.9),\n",
    "            'Lightgbm Regressor': LGBMRegressor(num_leaves=10, min_data_in_leaf=50, n_jobs=-1, random_state=42, n_estimators=500)   \n",
    "        }\n",
    "        \n",
    "        ## Mapped Model\n",
    "        if model == 'default':\n",
    "            model = modelMap[modelName]\n",
    "        else: model = model\n",
    "        \n",
    "        model.fit(XKFoldTraining, yKFoldTraining)\n",
    "\n",
    "        # Prediction\n",
    "        yhat = model.predict(XKFoldValidation)\n",
    "\n",
    "        #Performance\n",
    "        modelResult = mlError('Linear Regression', np.expm1(yKFoldValidation), np.expm1(yhat))\n",
    "        \n",
    "        #Store Performance of each KFold iteration\n",
    "        maeList.append(modelResult['MAE'].tolist())\n",
    "        mapeList.append(modelResult['MAPE'].tolist())\n",
    "        rmseList.append(modelResult['RMSE'].tolist())\n",
    "\n",
    "\n",
    "    dictResult = {\n",
    "                    'Model Name': [modelName],\n",
    "                    'MAE CV': [np.round(np.mean(maeList),2).astype(str) + ' +/- ' + np.round(np.std(maeList),2).astype(str)],\n",
    "                    'MAPE CV': [np.round(np.mean(mapeList),2).astype(str) + ' +/- ' + np.round(np.std(mapeList),2).astype(str)],\n",
    "                    'RMSE CV': [np.round(np.mean(rmseList),2).astype(str) + ' +/- ' + np.round(np.std(rmseList),2).astype(str)]\n",
    "                }\n",
    "\n",
    "    return pd.DataFrame(dictResult)\n",
    "\n",
    "\n",
    "def mean_percentage_error( y, yhat ):\n",
    "    return np.mean( ( y - yhat ) / y )\n",
    "\n",
    "def mean_absolute_percentage_error(y, yhat):\n",
    "    return np.mean(np.abs((y - yhat) / y))\n",
    "\n",
    "\n",
    "def mlError(modelName, y, yhat):\n",
    "    mae = mean_absolute_error(y, yhat)\n",
    "    mape = mean_absolute_percentage_error(y, yhat)\n",
    "    rmse = np.sqrt(mean_squared_error(y, yhat))\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "                            'ModelName': modelName,\n",
    "                            'MAE': mae,\n",
    "                            'MAPE': mape,\n",
    "                            'RMSE': rmse,\n",
    "                        }, index=[0])\n",
    "\n",
    "\n",
    "\n",
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    %pylab inline\n",
    "    \n",
    "    plt.style.use( 'bmh' )\n",
    "    plt.rcParams['figure.figsize'] = [25, 16]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    \n",
    "    display( HTML( '<style>.container { width:100% !important; }</style>') )\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option( 'display.expand_frame_repr', False )\n",
    "    \n",
    "    sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jupyter_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T02:28:14.396997Z",
     "start_time": "2020-12-05T02:28:10.514237Z"
    }
   },
   "outputs": [],
   "source": [
    "dfDataPreparation = pd.read_csv('../../01-Data/Results/01-FirstRoundCRISP/dfFeatureEngineering.csv', low_memory=False, parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T02:28:14.519146Z",
     "start_time": "2020-12-05T02:28:14.403862Z"
    }
   },
   "outputs": [],
   "source": [
    "dfRaw1 = dfDataPreparation.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numAttributes = dfRaw1.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "rs = RobustScaler()\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "#Competion Distance >> Presence of well defined outiliers\n",
    "numAttributes['CompetitionDistance'] = rs.fit_transform(numAttributes[['CompetitionDistance']].values)\n",
    "pickle.dump(rs, open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/CompetitionDistanceScaler.pkl', 'wb'))\n",
    "\n",
    "\n",
    "#Competion Time Month >> Presence of well defined outiliers\n",
    "numAttributes['CompetionTimeMonth'] = rs.fit_transform(numAttributes[['CompetionTimeMonth']].values)\n",
    "pickle.dump(rs, open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/CompetionTimeMonthScaler.pkl', 'wb'))\n",
    "\n",
    "\n",
    "#Promo Time Week\n",
    "numAttributes['PromoTimeWeek'] = mms.fit_transform(numAttributes[['PromoTimeWeek']].values)\n",
    "pickle.dump(mms, open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/PromoTimeWeekScaler.pkl', 'wb'))\n",
    "\n",
    "\n",
    "#Year\n",
    "numAttributes['Year'] = mms.fit_transform(numAttributes[['Year']].values)\n",
    "pickle.dump(mms, open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/YearScaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#State Holiday -> One Hot Encoding\n",
    "dfRaw1 = pd.get_dummies(dfRaw1, prefix=['StateHoliday'], columns=['StateHoliday'])\n",
    "\n",
    "#Store Type -> Label Encoding\n",
    "le = LabelEncoder()\n",
    "dfRaw1['StoreType'] = le.fit_transform(dfRaw1['StoreType'])\n",
    "pickle.dump(le, open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/StoreTypeScaler.pkl', 'wb'))\n",
    "\n",
    "#Assortment -> Ordinal Encoding\n",
    "dictAssortment = {\n",
    "                    'basic': 1,\n",
    "                    'extra': 2,\n",
    "                    'extended': 3\n",
    "                    }\n",
    "dfRaw1['Assortment'] = dfRaw1['Assortment'].map(dictAssortment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rossmann Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesRaw = pd.read_csv('../../01-Data/train.csv', low_memory=False)\n",
    "storeRaw = pd.read_csv('../../01-Data/store.csv', low_memory=False)\n",
    "\n",
    "dfRaw1 = salesRaw.merge(storeRaw, how='left', on='Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rossmann(object):\n",
    "    def __init__(self):\n",
    "        self.competitionDistanceScaler = pickle.load(open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/CompetitionDistanceScaler.pkl', 'rb'))\n",
    "        self.competionTimeMonthScaler =  pickle.load(open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/CompetionTimeMonthScaler.pkl', 'rb'))\n",
    "        self.promoTimeWeekScaler =       pickle.load(open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/PromoTimeWeekScaler.pkl', 'rb'))\n",
    "        self.yearScaler =                pickle.load(open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/YearScaler.pkl', 'rb'))\n",
    "        self.storeTypeScaler =           pickle.load(open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/StoreTypeScaler.pkl', 'rb'))\n",
    "\n",
    "\n",
    "        \n",
    "    def dataCleaning(self, dfRaw1):\n",
    "\n",
    "        ## Data Types\n",
    "        dfRaw1['Date'] = pd.to_datetime(dfRaw1['Date'])\n",
    "\n",
    "        ## Fillout NA\n",
    "        maxValueCompetitionDistance = dfRaw1['CompetitionDistance'].max()\n",
    "\n",
    "        # CompetitionDistance\n",
    "            #distance in meters to the nearest competitor store\n",
    "        dfRaw1['CompetitionDistance'] = dfRaw1['CompetitionDistance'].apply(lambda row: 200000.0 if math.isnan(row) else row)\n",
    "\n",
    "\n",
    "        # CompetitionOpenSinceMonth\n",
    "            #gives the approximate month of the time the nearest competitor was opened\n",
    "        dfRaw1['CompetitionOpenSinceMonth'] = dfRaw1.apply(lambda row: row['Date'].month if math.isnan(row['CompetitionOpenSinceMonth']) else row['CompetitionOpenSinceMonth'], axis=1)\n",
    "\n",
    "\n",
    "        # CompetitionOpenSinceYear\n",
    "            # gives the approximate year of the time the nearest competitor was opened\n",
    "        dfRaw1['CompetitionOpenSinceYear'] = dfRaw1.apply(lambda row: row['Date'].year if math.isnan(row['CompetitionOpenSinceYear']) else row['CompetitionOpenSinceYear'], axis=1)\n",
    "\n",
    "\n",
    "        # Promo2SinceWeek\n",
    "            #describes the calendar week when the store started participating in Promo2\n",
    "        dfRaw1['Promo2SinceWeek'] = dfRaw1.apply(lambda row: row['Date'].week if math.isnan(row['Promo2SinceWeek']) else row['Promo2SinceWeek'], axis=1)\n",
    "\n",
    "\n",
    "        # Promo2SinceYear\n",
    "            #describes the year when the store started participating in Promo2\n",
    "        dfRaw1['Promo2SinceYear'] = dfRaw1.apply(lambda row: row['Date'].year if math.isnan(row['Promo2SinceYear']) else row['Promo2SinceYear'], axis=1)\n",
    "\n",
    "\n",
    "        # PromoInterval\n",
    "            #describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew.\\\n",
    "            #E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store\n",
    "        monthMap = {\n",
    "                        1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'\n",
    "                    }\n",
    "\n",
    "        dfRaw1['PromoInterval'].fillna(0, inplace=True)\n",
    "        dfRaw1['MonthMap'] = dfRaw1['Date'].dt.month.map(monthMap)\n",
    "\n",
    "        dfRaw1['IsPromo'] = dfRaw1[['PromoInterval', 'MonthMap']].apply(lambda row: 0 if row['PromoInterval'] == 0 else 1 if row['MonthMap'] in row['PromoInterval'].split(',') else 0, axis=1)\n",
    "\n",
    "        # competiton\n",
    "        dfRaw1['CompetitionOpenSinceMonth'] = dfRaw1['CompetitionOpenSinceMonth'].astype(int)\n",
    "        dfRaw1['CompetitionOpenSinceYear'] = dfRaw1['CompetitionOpenSinceYear'].astype(int)\n",
    "\n",
    "        # promo2\n",
    "        dfRaw1['Promo2SinceWeek'] = dfRaw1['Promo2SinceWeek'].astype(int)\n",
    "        dfRaw1['Promo2SinceYear'] = dfRaw1['Promo2SinceYear'].astype(int)\n",
    "        \n",
    "        return dfRaw1\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def featureEngineering(self, df2):\n",
    "        \n",
    "        #year\n",
    "        df2['Year'] = df2['Date'].dt.year\n",
    "\n",
    "        #month\n",
    "        df2['Month'] = df2['Date'].dt.month\n",
    "\n",
    "        #day\n",
    "        df2['Day'] = df2['Date'].dt.day\n",
    "\n",
    "        #week of year\n",
    "        df2['WeekOfYear'] = df2['Date'].dt.weekofyear\n",
    "\n",
    "        #year week\n",
    "        df2['YearWeek'] = df2['Date'].dt.strftime('%Y-%W')\n",
    "\n",
    "        #Competion Sinse\n",
    "        df2['CompetionSinse'] = df2.apply(lambda row: datetime.datetime(year=row['CompetitionOpenSinceYear'], month=row['CompetitionOpenSinceMonth'], day=1), axis=1)\n",
    "        df2['CompetionTimeMonth'] = ((df2['Date'] - df2['CompetionSinse'])/30).apply(lambda row: row.days).astype(int)\n",
    "\n",
    "        #Promo Since\n",
    "        df2['PromoSince'] = df2['Promo2SinceYear'].astype(str) + '-' + df2['Promo2SinceWeek'].astype(str)\n",
    "        df2['PromoSince'] = df2['PromoSince'].apply(lambda row: datetime.datetime.strptime(row + '-1',  '%Y-%W-%w') - datetime.timedelta(days=7))\n",
    "        df2['PromoTimeWeek'] = ((dfdf2Raw1['Date'] - df2['PromoSince'])/7).apply(lambda row: row.days).astype(int)\n",
    "\n",
    "        #Assortment (level: a = basic, b = extra, c = extended)\n",
    "        level = {\n",
    "            'a' : 'basic', 'b' : 'extra', 'c' : 'extended'\n",
    "        }\n",
    "        df2['Assortment'] = df2['Assortment'].map(level)\n",
    "\n",
    "        # State Holiday (a = public holiday, b = Easter holiday, c = Christmas, 0 = None)\n",
    "        holiday = {\n",
    "            'a' : 'public holiday', 'b' : 'Easter holiday', 'c' : 'Christmas'\n",
    "        }\n",
    "        df2['StateHoliday'] = df2['StateHoliday'].map(holiday)\n",
    "        df2['StateHoliday'].fillna('Regular Day', inplace=True)\n",
    "\n",
    "        ## Row Fitering\n",
    "        df2 = df2[(df2['Open'] != 0) & (df2['Sales'] > 0)]\n",
    "\n",
    "        ## Columns Filtering\n",
    "        toDrop = ['Customers', 'Open', 'PromoInterval', 'MonthMap']\n",
    "        df2.drop(toDrop, axis=1, inplace=True)\n",
    "        \n",
    "        return df2\n",
    "\n",
    "    \n",
    "    def dataPreparation(self, df3):\n",
    "        \n",
    "        #Competion Distance >> Presence of well defined outiliers\n",
    "        df3['CompetitionDistance'] = self.competitionDistanceScaler.fit_transform(df3[['CompetitionDistance']].values)\n",
    "\n",
    "        #Competion Time Month >> Presence of well defined outiliers\n",
    "        df3['CompetionTimeMonth'] = self.competionTimeMonthScaler.fit_transform(df3[['CompetionTimeMonth']].values)\n",
    "\n",
    "        #Promo Time Week\n",
    "        df3['PromoTimeWeek'] = self.promoTimeWeekScaler.fit_transform(df3[['PromoTimeWeek']].values)\n",
    "\n",
    "        #Year\n",
    "        df3['Year'] = self.yearScaler.fit_transform(df3[['Year']].values)\n",
    "\n",
    "        ### Encoding\n",
    "        #State Holiday -> One Hot Encoding\n",
    "        df3 = pd.get_dummies(df3, prefix=['StateHoliday'], columns=['StateHoliday'])\n",
    "\n",
    "        #Store Type -> Label Encoding\n",
    "        df3['StoreType'] = self.storeTypeScaler.fit_transform(df3['StoreType'])\n",
    "\n",
    "        #Assortment -> Ordinal Encoding\n",
    "        dictAssortment = {\n",
    "                            'basic': 1,\n",
    "                            'extra': 2,\n",
    "                            'extended': 3\n",
    "                            }\n",
    "        df3['Assortment'] = df3['Assortment'].map(dictAssortment)\n",
    "\n",
    "        ### Nature Transformation\n",
    "        #Month\n",
    "        df3['MonthSin'] = df3['Month'].apply(lambda row: np.sin(row * (2 * np.pi/12)))\n",
    "        df3['MonthCos'] = df3['Month'].apply(lambda row: np.cos(row * (2 * np.pi/12)))\n",
    "        #Day\n",
    "        df3['DaySin'] = df3['Day'].apply(lambda row: np.sin(row * (2 * np.pi/30)))\n",
    "        df3['DayCos'] = df3['Day'].apply(lambda row: np.cos(row * (2 * np.pi/30)))\n",
    "        #Week of Year\n",
    "        df3['WeekOfYearSin'] = df3['WeekOfYear'].apply(lambda row: np.sin(row * (2 * np.pi/52)))\n",
    "        df3['WeekOfYearCos'] = df3['WeekOfYear'].apply(lambda row: np.cos(row * (2 * np.pi/52)))\n",
    "        #Day of Week\n",
    "        df3['DayOfWeekSin'] = df3['DayOfWeek'].apply(lambda row: np.sin(row * (2 * np.pi/7)))\n",
    "        df3['DayOfWeekCos'] = df3['DayOfWeek'].apply(lambda row: np.cos(row * (2 * np.pi/7)))\n",
    "        \n",
    "        colsSelected = ['Store','Promo','StoreType','Assortment','CompetitionDistance','CompetitionOpenSinceMonth',\n",
    "                                'CompetitionOpenSinceYear','Promo2','Promo2SinceWeek','Promo2SinceYear','CompetionTimeMonth',\n",
    "                                'PromoTimeWeek','MonthSin','MonthCos','DaySin','DayCos','WeekOfYearSin','WeekOfYearCos','DayOfWeekSin',\n",
    "                                'DayOfWeekCos']\n",
    "        \n",
    "        return df3[colsSelected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, Response\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from rossmann.Rossmann import Rossmann\n",
    "\n",
    "# Loding Model\n",
    "model = pickle.load(open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/model/modelRossmann.pkl', 'rb' ))\n",
    "\n",
    "# Initialize API\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/rossmann/predict', methods=['POST'])\n",
    "def rossmanPredict():\n",
    "    testJSON = request.get_json()\n",
    "    \n",
    "    if testJSON: #there is data\n",
    "        if isinstance(testJSON, dict):\n",
    "            testeRaw = pd.DataFrame(testJSON, index=[0]) #unique example\n",
    "        else:\n",
    "            testeRaw = pd.DataFrame(testJSON, columns=testJSON[0].keys()) #multiple examples\n",
    "    \n",
    "        # Instantiate\n",
    "        pipeline = Rossmann()\n",
    "        \n",
    "        # Data Cleaning\n",
    "        df1 = pipeline.dataCleaning(testeRaw)\n",
    "        # Feature Engineering\n",
    "        df2 = pipeline.featureEngineering(df1)\n",
    "        # Data Preparation\n",
    "        df3 = pipeline.dataPreparation(df2)\n",
    "        # Prediction\n",
    "        dfResponse = pipeline.getPrediction(model, testeRaw, df3)\n",
    "        \n",
    "        return dfResponse\n",
    "    \n",
    "    else:\n",
    "        return Response('{}', status=200, mimetype='application/json')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run('0.0.0.0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
