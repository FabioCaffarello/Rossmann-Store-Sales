{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "import pickle\n",
    "import json\n",
    "import requests\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T02:28:14.396997Z",
     "start_time": "2020-12-05T02:28:10.514237Z"
    }
   },
   "outputs": [],
   "source": [
    "dfDataPreparation = pd.read_csv('../../01-Data/Results/01-FirstRoundCRISP/dfFeatureEngineering.csv', low_memory=False, parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T02:28:14.519146Z",
     "start_time": "2020-12-05T02:28:14.403862Z"
    }
   },
   "outputs": [],
   "source": [
    "dfRaw1 = dfDataPreparation.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numAttributes = dfRaw1.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "rs = RobustScaler()\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "#Competion Distance >> Presence of well defined outiliers\n",
    "numAttributes['CompetitionDistance'] = rs.fit_transform(numAttributes[['CompetitionDistance']].values)\n",
    "pickle.dump(rs, open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/CompetitionDistanceScaler.pkl', 'wb'))\n",
    "\n",
    "\n",
    "#Competion Time Month >> Presence of well defined outiliers\n",
    "numAttributes['CompetionTimeMonth'] = rs.fit_transform(numAttributes[['CompetionTimeMonth']].values)\n",
    "pickle.dump(rs, open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/CompetionTimeMonthScaler.pkl', 'wb'))\n",
    "\n",
    "\n",
    "#Promo Time Week\n",
    "numAttributes['PromoTimeWeek'] = mms.fit_transform(numAttributes[['PromoTimeWeek']].values)\n",
    "pickle.dump(mms, open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/PromoTimeWeekScaler.pkl', 'wb'))\n",
    "\n",
    "\n",
    "#Year\n",
    "numAttributes['Year'] = mms.fit_transform(numAttributes[['Year']].values)\n",
    "pickle.dump(mms, open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/YearScaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#State Holiday -> One Hot Encoding\n",
    "dfRaw1 = pd.get_dummies(dfRaw1, prefix=['StateHoliday'], columns=['StateHoliday'])\n",
    "\n",
    "#Store Type -> Label Encoding\n",
    "le = LabelEncoder()\n",
    "dfRaw1['StoreType'] = le.fit_transform(dfRaw1['StoreType'])\n",
    "pickle.dump(le, open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/StoreTypeScaler.pkl', 'wb'))\n",
    "\n",
    "#Assortment -> Ordinal Encoding\n",
    "dictAssortment = {\n",
    "                    'basic': 1,\n",
    "                    'extra': 2,\n",
    "                    'extended': 3\n",
    "                    }\n",
    "dfRaw1['Assortment'] = dfRaw1['Assortment'].map(dictAssortment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rossmann Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import math\n",
    "# import datetime\n",
    "\n",
    "\n",
    "\n",
    "# class Rossmann(object):\n",
    "#     def __init__(self):\n",
    "#         self.home_path = 'D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/'\n",
    "#         self.competitionDistanceScaler = pickle.load(open(self.homep_path + 'parameter/CompetitionDistanceScaler.pkl', 'rb'))\n",
    "#         self.competionTimeMonthScaler =  pickle.load(open(self.homep_path + 'parameter/CompetionTimeMonthScaler.pkl', 'rb'))\n",
    "#         self.promoTimeWeekScaler =       pickle.load(open(self.homep_path + 'parameter/PromoTimeWeekScaler.pkl', 'rb'))\n",
    "#         self.yearScaler =                pickle.load(open(self.homep_path + 'parameter/YearScaler.pkl', 'rb'))\n",
    "#         self.storeTypeScaler =           pickle.load(open(self.homep_path + 'parameter/StoreTypeScaler.pkl', 'rb'))\n",
    "\n",
    "\n",
    "        \n",
    "#     def dataCleaning(self, dfRaw1):\n",
    "\n",
    "#         ## Data Types\n",
    "#         dfRaw1['Date'] = pd.to_datetime(dfRaw1['Date'])\n",
    "\n",
    "#         ## Fillout NA\n",
    "#         maxValueCompetitionDistance = dfRaw1['CompetitionDistance'].max()\n",
    "\n",
    "#         # CompetitionDistance\n",
    "#             #distance in meters to the nearest competitor store\n",
    "#         dfRaw1['CompetitionDistance'] = dfRaw1['CompetitionDistance'].apply(lambda row: 200000.0 if math.isnan(row) else row)\n",
    "\n",
    "\n",
    "#         # CompetitionOpenSinceMonth\n",
    "#             #gives the approximate month of the time the nearest competitor was opened\n",
    "#         dfRaw1['CompetitionOpenSinceMonth'] = dfRaw1.apply(lambda row: row['Date'].month if math.isnan(row['CompetitionOpenSinceMonth']) else row['CompetitionOpenSinceMonth'], axis=1)\n",
    "\n",
    "\n",
    "#         # CompetitionOpenSinceYear\n",
    "#             # gives the approximate year of the time the nearest competitor was opened\n",
    "#         dfRaw1['CompetitionOpenSinceYear'] = dfRaw1.apply(lambda row: row['Date'].year if math.isnan(row['CompetitionOpenSinceYear']) else row['CompetitionOpenSinceYear'], axis=1)\n",
    "\n",
    "\n",
    "#         # Promo2SinceWeek\n",
    "#             #describes the calendar week when the store started participating in Promo2\n",
    "#         dfRaw1['Promo2SinceWeek'] = dfRaw1.apply(lambda row: row['Date'].week if math.isnan(row['Promo2SinceWeek']) else row['Promo2SinceWeek'], axis=1)\n",
    "\n",
    "\n",
    "#         # Promo2SinceYear\n",
    "#             #describes the year when the store started participating in Promo2\n",
    "#         dfRaw1['Promo2SinceYear'] = dfRaw1.apply(lambda row: row['Date'].year if math.isnan(row['Promo2SinceYear']) else row['Promo2SinceYear'], axis=1)\n",
    "\n",
    "\n",
    "#         # PromoInterval\n",
    "#             #describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew.\\\n",
    "#             #E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store\n",
    "#         monthMap = {\n",
    "#                         1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'\n",
    "#                     }\n",
    "\n",
    "#         dfRaw1['PromoInterval'].fillna(0, inplace=True)\n",
    "#         dfRaw1['MonthMap'] = dfRaw1['Date'].dt.month.map(monthMap)\n",
    "\n",
    "#         dfRaw1['IsPromo'] = dfRaw1[['PromoInterval', 'MonthMap']].apply(lambda row: 0 if row['PromoInterval'] == 0 else 1 if row['MonthMap'] in row['PromoInterval'].split(',') else 0, axis=1)\n",
    "\n",
    "#         # competiton\n",
    "#         dfRaw1['CompetitionOpenSinceMonth'] = dfRaw1['CompetitionOpenSinceMonth'].astype(int)\n",
    "#         dfRaw1['CompetitionOpenSinceYear'] = dfRaw1['CompetitionOpenSinceYear'].astype(int)\n",
    "\n",
    "#         # promo2\n",
    "#         dfRaw1['Promo2SinceWeek'] = dfRaw1['Promo2SinceWeek'].astype(int)\n",
    "#         dfRaw1['Promo2SinceYear'] = dfRaw1['Promo2SinceYear'].astype(int)\n",
    "        \n",
    "#         return dfRaw1\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#     def featureEngineering(self, df2):\n",
    "        \n",
    "#         #year\n",
    "#         df2['Year'] = df2['Date'].dt.year\n",
    "\n",
    "#         #month\n",
    "#         df2['Month'] = df2['Date'].dt.month\n",
    "\n",
    "#         #day\n",
    "#         df2['Day'] = df2['Date'].dt.day\n",
    "\n",
    "#         #week of year\n",
    "#         df2['WeekOfYear'] = df2['Date'].dt.weekofyear\n",
    "\n",
    "#         #year week\n",
    "#         df2['YearWeek'] = df2['Date'].dt.strftime('%Y-%W')\n",
    "\n",
    "#         #Competion Sinse\n",
    "#         df2['CompetionSinse'] = df2.apply(lambda row: datetime.datetime(year=row['CompetitionOpenSinceYear'], month=row['CompetitionOpenSinceMonth'], day=1), axis=1)\n",
    "#         df2['CompetionTimeMonth'] = ((df2['Date'] - df2['CompetionSinse'])/30).apply(lambda row: row.days).astype(int)\n",
    "\n",
    "#         #Promo Since\n",
    "#         df2['PromoSince'] = df2['Promo2SinceYear'].astype(str) + '-' + df2['Promo2SinceWeek'].astype(str)\n",
    "#         df2['PromoSince'] = df2['PromoSince'].apply(lambda row: datetime.datetime.strptime(row + '-1',  '%Y-%W-%w') - datetime.timedelta(days=7))\n",
    "#         df2['PromoTimeWeek'] = ((dfdf2Raw1['Date'] - df2['PromoSince'])/7).apply(lambda row: row.days).astype(int)\n",
    "\n",
    "#         #Assortment (level: a = basic, b = extra, c = extended)\n",
    "#         level = {\n",
    "#             'a' : 'basic', 'b' : 'extra', 'c' : 'extended'\n",
    "#         }\n",
    "#         df2['Assortment'] = df2['Assortment'].map(level)\n",
    "\n",
    "#         # State Holiday (a = public holiday, b = Easter holiday, c = Christmas, 0 = None)\n",
    "#         holiday = {\n",
    "#             'a' : 'public holiday', 'b' : 'Easter holiday', 'c' : 'Christmas'\n",
    "#         }\n",
    "#         df2['StateHoliday'] = df2['StateHoliday'].map(holiday)\n",
    "#         df2['StateHoliday'].fillna('Regular Day', inplace=True)\n",
    "\n",
    "#         ## Row Fitering\n",
    "#         df2 = df2[df2['Open'] != 0]\n",
    "\n",
    "#         ## Columns Filtering\n",
    "#         toDrop = ['Open', 'PromoInterval', 'MonthMap']\n",
    "#         df2.drop(toDrop, axis=1, inplace=True)\n",
    "        \n",
    "#         return df2\n",
    "\n",
    "    \n",
    "#     def dataPreparation(self, df3):\n",
    "        \n",
    "#         #Competion Distance >> Presence of well defined outiliers\n",
    "#         df3['CompetitionDistance'] = self.competitionDistanceScaler.fit_transform(df3[['CompetitionDistance']].values)\n",
    "\n",
    "#         #Competion Time Month >> Presence of well defined outiliers\n",
    "#         df3['CompetionTimeMonth'] = self.competionTimeMonthScaler.fit_transform(df3[['CompetionTimeMonth']].values)\n",
    "\n",
    "#         #Promo Time Week\n",
    "#         df3['PromoTimeWeek'] = self.promoTimeWeekScaler.fit_transform(df3[['PromoTimeWeek']].values)\n",
    "\n",
    "#         #Year\n",
    "#         df3['Year'] = self.yearScaler.fit_transform(df3[['Year']].values)\n",
    "\n",
    "#         ### Encoding\n",
    "#         #State Holiday -> One Hot Encoding\n",
    "#         df3 = pd.get_dummies(df3, prefix=['StateHoliday'], columns=['StateHoliday'])\n",
    "\n",
    "#         #Store Type -> Label Encoding\n",
    "#         df3['StoreType'] = self.storeTypeScaler.fit_transform(df3['StoreType'])\n",
    "\n",
    "#         #Assortment -> Ordinal Encoding\n",
    "#         dictAssortment = {\n",
    "#                             'basic': 1,\n",
    "#                             'extra': 2,\n",
    "#                             'extended': 3\n",
    "#                             }\n",
    "#         df3['Assortment'] = df3['Assortment'].map(dictAssortment)\n",
    "\n",
    "#         ### Nature Transformation\n",
    "#         #Month\n",
    "#         df3['MonthSin'] = df3['Month'].apply(lambda row: np.sin(row * (2 * np.pi/12)))\n",
    "#         df3['MonthCos'] = df3['Month'].apply(lambda row: np.cos(row * (2 * np.pi/12)))\n",
    "#         #Day\n",
    "#         df3['DaySin'] = df3['Day'].apply(lambda row: np.sin(row * (2 * np.pi/30)))\n",
    "#         df3['DayCos'] = df3['Day'].apply(lambda row: np.cos(row * (2 * np.pi/30)))\n",
    "#         #Week of Year\n",
    "#         df3['WeekOfYearSin'] = df3['WeekOfYear'].apply(lambda row: np.sin(row * (2 * np.pi/52)))\n",
    "#         df3['WeekOfYearCos'] = df3['WeekOfYear'].apply(lambda row: np.cos(row * (2 * np.pi/52)))\n",
    "#         #Day of Week\n",
    "#         df3['DayOfWeekSin'] = df3['DayOfWeek'].apply(lambda row: np.sin(row * (2 * np.pi/7)))\n",
    "#         df3['DayOfWeekCos'] = df3['DayOfWeek'].apply(lambda row: np.cos(row * (2 * np.pi/7)))\n",
    "        \n",
    "#         colsSelected = ['Store','Promo','StoreType','Assortment','CompetitionDistance','CompetitionOpenSinceMonth',\n",
    "#                                 'CompetitionOpenSinceYear','Promo2','Promo2SinceWeek','Promo2SinceYear','CompetionTimeMonth',\n",
    "#                                 'PromoTimeWeek','MonthSin','MonthCos','DaySin','DayCos','WeekOfYearSin','WeekOfYearCos','DayOfWeekSin',\n",
    "#                                 'DayOfWeekCos']\n",
    "        \n",
    "#         return df3[colsSelected]\n",
    "\n",
    "\n",
    "#     def getPrediction(self, model, originalData, testData):\n",
    "#         # Prediction\n",
    "#         pred = model.predict(testData)\n",
    "\n",
    "#         # Join pred into original Data\n",
    "#         originalData['Prediction'] = np.exp1m(pred)\n",
    "\n",
    "#         return originalData.to_json(orient='records', date_format='iso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask import Flask, request, Response\n",
    "# import pandas as pd\n",
    "# import pickle\n",
    "# #from rossmann.Rossmann import Rossmann\n",
    "\n",
    "# # Loding Model\n",
    "# model = pickle.load(open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/model/modelRossmann.pkl', 'rb' ))\n",
    "\n",
    "# # Initialize API\n",
    "# app = Flask(__name__)\n",
    "\n",
    "# @app.route('/rossmann/predict', methods=['POST'])\n",
    "# def rossmanPredict():\n",
    "#     testJSON = request.get_json()\n",
    "    \n",
    "#     if testJSON: #there is data\n",
    "#         if isinstance(testJSON, dict):\n",
    "#             testeRaw = pd.DataFrame(testJSON, index=[0]) #unique example\n",
    "#         else:\n",
    "#             testeRaw = pd.DataFrame(testJSON, columns=testJSON[0].keys()) #multiple examples\n",
    "    \n",
    "#         # Instantiate\n",
    "#         pipeline = Rossmann()\n",
    "        \n",
    "#         # Data Cleaning\n",
    "#         df1 = pipeline.dataCleaning(testeRaw)\n",
    "#         # Feature Engineering\n",
    "#         df2 = pipeline.featureEngineering(df1)\n",
    "#         # Data Preparation\n",
    "#         df3 = pipeline.dataPreparation(df2)\n",
    "#         # Prediction\n",
    "#         dfResponse = pipeline.getPrediction(model, testeRaw, df3)\n",
    "        \n",
    "#         return dfResponse\n",
    "    \n",
    "#     else:\n",
    "#         return Response('{}', status=200, mimetype='application/json')\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run('0.0.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salesRaw = pd.read_csv('../../01-Data/train.csv', low_memory=False)\n",
    "storeRaw = pd.read_csv('../../01-Data/store.csv', low_memory=False)\n",
    "testRaw = pd.read_csv('../../01-Data/test.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Test dataset + Store\n",
    "dfTest = pd.merge(testRaw, storeRaw, how='left', on='Store')\n",
    "\n",
    "# Choose Store for Prediction\n",
    "dfTest = dfTest[dfTest['Store'] == 22]\n",
    "\n",
    "# Remove Closed Days\n",
    "dfTest = dfTest[dfTest['Open'] != 0]\n",
    "dfTest = dfTest[~dfTest['Open'].isnull()]\n",
    "dfTest = dfTest.drop('Id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to JSON\n",
    "data = json.dumps(dfTest.to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code 200\n"
     ]
    }
   ],
   "source": [
    "## API Call\n",
    "url = 'http://127.0.0.1:5000/rossmann/predict'\n",
    "header = {'Content-Type': 'application/json'}\n",
    "data = data\n",
    "\n",
    "r = requests.post(url, data=data, headers=header)\n",
    "print('Status Code {}'.format(r.status_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'comlumns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-d38786440946>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfResponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomlumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'comlumns'"
     ]
    }
   ],
   "source": [
    "dfResponse = pd.DataFrame(r.json(), comlumns=r.json()[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
