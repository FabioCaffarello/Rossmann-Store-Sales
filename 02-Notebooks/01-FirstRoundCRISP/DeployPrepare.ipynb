{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidation(XTraining, kfold, modelName, model='default', verbose=False):\n",
    "    maeList = []\n",
    "    mapeList = []\n",
    "    rmseList = []\n",
    "\n",
    "    for k in reversed(range(1, kfold+1)):\n",
    "        if verbose:\n",
    "            print(f'\\nKFold Number: {k}')\n",
    "        # Start and End Date for Validation\n",
    "        startDateValid = XTraining['Date'].max() - datetime.timedelta(days=k*6*7)\n",
    "        endDateValid = XTraining['Date'].max() - datetime.timedelta(days=(k-1)*6*7)\n",
    "\n",
    "        # Filtering Dataset\n",
    "        training = XTraining[XTraining['Date'] < startDateValid]\n",
    "        validation = XTraining[(XTraining['Date'] >= startDateValid) & (XTraining['Date'] <= endDateValid)]\n",
    "\n",
    "        # Training and Validation Dataset\n",
    "        # Training\n",
    "        XKFoldTraining = training.drop(['Date', 'Sales'], axis=1)\n",
    "        yKFoldTraining = training['Sales']\n",
    "\n",
    "        # Validation\n",
    "        XKFoldValidation = validation.drop(['Date', 'Sales'], axis=1)\n",
    "        yKFoldValidation = validation['Sales']\n",
    "\n",
    "        # Model\n",
    "        ## Model Map\n",
    "        modelMap = {\n",
    "            'Linear Regression': LinearRegression(),\n",
    "            'Lasso': Lasso(alpha=0.01),\n",
    "            'Random Forest Regressor': RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42),\n",
    "            'XGBoost Regressor': xgb.XGBRegressor( objective='reg:squarederror', n_estimators=500, eta=0.01, max_depth=10, \n",
    "                                                      subsample=0.7, colsample_bytree=0.9),\n",
    "            'Lightgbm Regressor': LGBMRegressor(num_leaves=10, min_data_in_leaf=50, n_jobs=-1, random_state=42, n_estimators=500)   \n",
    "        }\n",
    "        \n",
    "        ## Mapped Model\n",
    "        if model == 'default':\n",
    "            model = modelMap[modelName]\n",
    "        else: model = model\n",
    "        \n",
    "        model.fit(XKFoldTraining, yKFoldTraining)\n",
    "\n",
    "        # Prediction\n",
    "        yhat = model.predict(XKFoldValidation)\n",
    "\n",
    "        #Performance\n",
    "        modelResult = mlError('Linear Regression', np.expm1(yKFoldValidation), np.expm1(yhat))\n",
    "        \n",
    "        #Store Performance of each KFold iteration\n",
    "        maeList.append(modelResult['MAE'].tolist())\n",
    "        mapeList.append(modelResult['MAPE'].tolist())\n",
    "        rmseList.append(modelResult['RMSE'].tolist())\n",
    "\n",
    "\n",
    "    dictResult = {\n",
    "                    'Model Name': [modelName],\n",
    "                    'MAE CV': [np.round(np.mean(maeList),2).astype(str) + ' +/- ' + np.round(np.std(maeList),2).astype(str)],\n",
    "                    'MAPE CV': [np.round(np.mean(mapeList),2).astype(str) + ' +/- ' + np.round(np.std(mapeList),2).astype(str)],\n",
    "                    'RMSE CV': [np.round(np.mean(rmseList),2).astype(str) + ' +/- ' + np.round(np.std(rmseList),2).astype(str)]\n",
    "                }\n",
    "\n",
    "    return pd.DataFrame(dictResult)\n",
    "\n",
    "\n",
    "def mean_percentage_error( y, yhat ):\n",
    "    return np.mean( ( y - yhat ) / y )\n",
    "\n",
    "def mean_absolute_percentage_error(y, yhat):\n",
    "    return np.mean(np.abs((y - yhat) / y))\n",
    "\n",
    "\n",
    "def mlError(modelName, y, yhat):\n",
    "    mae = mean_absolute_error(y, yhat)\n",
    "    mape = mean_absolute_percentage_error(y, yhat)\n",
    "    rmse = np.sqrt(mean_squared_error(y, yhat))\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "                            'ModelName': modelName,\n",
    "                            'MAE': mae,\n",
    "                            'MAPE': mape,\n",
    "                            'RMSE': rmse,\n",
    "                        }, index=[0])\n",
    "\n",
    "\n",
    "\n",
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    %pylab inline\n",
    "    \n",
    "    plt.style.use( 'bmh' )\n",
    "    plt.rcParams['figure.figsize'] = [25, 16]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    \n",
    "    display( HTML( '<style>.container { width:100% !important; }</style>') )\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option( 'display.expand_frame_repr', False )\n",
    "    \n",
    "    sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jupyter_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T02:28:14.396997Z",
     "start_time": "2020-12-05T02:28:10.514237Z"
    }
   },
   "outputs": [],
   "source": [
    "dfDataPreparation = pd.read_csv('../../01-Data/Results/01-FirstRoundCRISP/dfFeatureEngineering.csv', low_memory=False, parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T02:28:14.519146Z",
     "start_time": "2020-12-05T02:28:14.403862Z"
    }
   },
   "outputs": [],
   "source": [
    "dfRaw1 = dfDataPreparation.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/CompetitionDistanceScaler.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-fc03892586c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#Competion Distance >> Presence of well defined outiliers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mnumAttributes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CompetitionDistance'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumAttributes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CompetitionDistance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/CompetitionDistanceScaler.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/CompetitionDistanceScaler.pkl'"
     ]
    }
   ],
   "source": [
    "numAttributes = dfRaw1.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "rs = RobustScaler()\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "#Competion Distance >> Presence of well defined outiliers\n",
    "numAttributes['CompetitionDistance'] = rs.fit_transform(numAttributes[['CompetitionDistance']].values)\n",
    "pickle.dump(rs, open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/CompetitionDistanceScaler.pkl', 'wb'))\n",
    "\n",
    "\n",
    "#Competion Time Month >> Presence of well defined outiliers\n",
    "numAttributes['CompetionTimeMonth'] = rs.fit_transform(numAttributes[['CompetionTimeMonth']].values)\n",
    "pickle.dump(rs, open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/CompetionTimeMonthScaler.pkl', 'wb'))\n",
    "\n",
    "\n",
    "#Promo Time Week\n",
    "numAttributes['PromoTimeWeek'] = mms.fit_transform(numAttributes[['PromoTimeWeek']].values)\n",
    "pickle.dump(mms, open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/PromoTimeWeekScaler.pkl', 'wb'))\n",
    "\n",
    "\n",
    "#Year\n",
    "numAttributes['Year'] = mms.fit_transform(numAttributes[['Year']].values)\n",
    "pickle.dump(mms, open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/YearScaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#State Holiday -> One Hot Encoding\n",
    "dfRaw1 = pd.get_dummies(dfRaw1, prefix=['StateHoliday'], columns=['StateHoliday'])\n",
    "\n",
    "#Store Type -> Label Encoding\n",
    "le = LabelEncoder()\n",
    "dfRaw1['StoreType'] = le.fit_transform(dfRaw1['StoreType'])\n",
    "pickle.dump(le, open('D:/01-DataScience/04-Projetos/00-Git/Rossmann-Store-Sales/02-Notebooks/01-FirstRoundCRISP/parameter/StoreTypeScaler.pkl', 'wb'))\n",
    "\n",
    "#Assortment -> Ordinal Encoding\n",
    "dictAssortment = {\n",
    "                    'basic': 1,\n",
    "                    'extra': 2,\n",
    "                    'extended': 3\n",
    "                    }\n",
    "dfRaw1['Assortment'] = dfRaw1['Assortment'].map(dictAssortment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rossmann Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
